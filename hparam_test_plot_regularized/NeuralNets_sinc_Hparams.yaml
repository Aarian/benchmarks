#Some Hyper Params
base_channels: 32
kernel_size_sinc: 125
CHANNEL_NUM: 256
DIM_CNN_MLP: 277
lr: 0.001
lr_final: 0.0001
batch_size: 16
number_of_epochs: 60
#Initial Settings

seed: 12345
__set_seed: !apply:torch.manual_seed [!ref <seed>]
output_folder: !ref Results_test_plot_regularized/Ultrasound_sinc/
save_folder: !ref <output_folder>/save
loss_image_folder: !ref <output_folder>/LossImages
train_log: !ref <output_folder>/train_log.txt
#train_epoch_test_log: !ref <output_folder>/train_epoch_test_log.txt
json_folder: !ref ./json_folder


train_logger: !new:speechbrain.utils.train_logger.FileTrainLogger
    save_file: !ref <train_log>


train_epoch_test_log: !new:speechbrain.utils.train_logger.FileTrainLogger
    save_file: !ref <train_epoch_test_log>


#padding: !ref <kernel_size> // 2

# Data files
train_json: !ref <json_folder>/train.json
valid_json: !ref <json_folder>/valid.json
test_json: !ref <json_folder>/test.json


#sorting: ascending
sorting: random


train_dataloader_opts:
    batch_size: !ref <batch_size>
    shuffle: True
    
valid_dataloader_opts:
   batch_size: !ref <batch_size>

test_dataloader_opts:
   batch_size: !ref <batch_size>


epoch_counter: !new:speechbrain.utils.epoch_loop.EpochCounter
    limit: !ref <number_of_epochs>

lr_annealing: !new:speechbrain.nnet.schedulers.LinearScheduler
    initial_value: !ref <lr>
    final_value: !ref <lr_final>
    epoch_count: !ref <number_of_epochs>



snr_white_low: 0 #19.0
snr_white_delta: 10 #19.1
snr_white_high: !ref <snr_white_low> + <snr_white_delta>
add_noise_white: !new:speechbrain.processing.speech_augmentation.AddNoise
    snr_low: !ref <snr_white_low>
    snr_high: !ref <snr_white_high>
    noise_sample_rate: 100000000
    clean_sample_rate: 100000000


layer1: !new:speechbrain.nnet.CNN.SincConv
  in_channels: 1
  out_channels: !ref <CHANNEL_NUM>
  stride: 2
  sample_rate: 100000000
  kernel_size: !ref <kernel_size_sinc>

layer2: !new:torch.nn.Conv1d
  in_channels: !ref <CHANNEL_NUM>
  out_channels: !ref <CHANNEL_NUM>//2
  kernel_size: 4
  stride: 2
  padding: 1
  bias: False

layer3: !new:torch.nn.Conv1d
  in_channels: !ref <CHANNEL_NUM>//2
  out_channels: !ref <CHANNEL_NUM>//4
  kernel_size: 4
  stride: 2
  padding: 1
  bias: False

layer4: !new:torch.nn.Conv1d
  in_channels: !ref <CHANNEL_NUM>//4
  out_channels: !ref <CHANNEL_NUM>//8
  kernel_size: 3
  stride: 1
  padding: 1
  bias: False

layer5: !new:torch.nn.Conv1d
  in_channels: !ref <CHANNEL_NUM>//8
  out_channels: 1
  kernel_size: 4
  stride: 1
  padding: 0
  bias: False


Relue: !new:torch.nn.ReLU
  inplace: True

LeakyRelue: !new:torch.nn.LeakyReLU
  inplace: True

Batch_norm_1d_layer_2: !new:torch.nn.BatchNorm1d
  num_features: !ref <CHANNEL_NUM>//2

Batch_norm_1d_layer_3: !new:torch.nn.BatchNorm1d
  num_features: !ref <CHANNEL_NUM>//4

Batch_norm_1d_layer_4: !new:torch.nn.BatchNorm1d
  num_features: !ref <CHANNEL_NUM>//8

Avg_pooling_1d: !new:torch.nn.AvgPool1d
  kernel_size: 3
  stride: 2

Dropout_1d: !new:torch.nn.Dropout1d
  p: 0.9 #0.5

LayerNorm: !new:torch.nn.LayerNorm
  normalized_shape: !ref <DIM_CNN_MLP>

flatten_L: !new:torch.nn.Flatten

MLP_L1: !new:torch.nn.Linear
  in_features: !ref <DIM_CNN_MLP>
  out_features: 16

MLP_L2: !new:torch.nn.Linear
  in_features: 16
  out_features: 8

MLP_L3: !new:torch.nn.Linear
  in_features: 8
  out_features: 1


# Optimizer
optim: !name:torch.optim.Adam
  lr: !ref <lr>

scheduler: !name:torch.optim.lr_scheduler.LinearLR
  optimizer: !ref <optim>
  start_factor: 1.0
  end_factor: 0.5
  total_iters: 30


# Loss function

loss: !new:torch.nn.MSELoss

#Modules

SincBlock: !new:torch.nn.Sequential
  - !ref <layer1>
  - !ref <Relue>

CnnBlock: !new:torch.nn.Sequential
  - !ref <layer2>
  - !ref <Batch_norm_1d_layer_2>
  - !ref <LeakyRelue>
  - !ref <Dropout_1d>
  - !ref <layer3>
  - !ref <Batch_norm_1d_layer_3>
  - !ref <Relue>
  - !ref <Dropout_1d>
  - !ref <layer4>
  - !ref <Batch_norm_1d_layer_4>
  - !ref <Relue>
  - !ref <Avg_pooling_1d>
  - !ref <Dropout_1d>
  - !ref <layer5>
  - !ref <LeakyRelue>
  - !ref <LayerNorm>
  - !ref <Dropout_1d>
  - !ref <flatten_L> 

MLPBlock: !new:torch.nn.Sequential
  - !ref <MLP_L1>
  - !ref <LeakyRelue>
  - !ref <Dropout_1d>
  - !ref <MLP_L2>
  - !ref <LeakyRelue>
  - !ref <Dropout_1d>
  - !ref <MLP_L3>

modules:
  SincBlock: !ref <SincBlock>
  CnnBlock: !ref <CnnBlock>
  MLPBlock: !ref <MLPBlock>



model: !new:torch.nn.ModuleList
- [!ref <SincBlock>, !ref <CnnBlock>, !ref <MLPBlock>]





###### Check pointing

checkpointer: !new:speechbrain.utils.checkpoints.Checkpointer
    checkpoints_dir: !ref <save_folder>
    recoverables:
        model: !ref <model>
        counter: !ref <epoch_counter>