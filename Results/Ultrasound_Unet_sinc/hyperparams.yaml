# Generated 2023-10-21 from:
# /home/arian/PycharmProjects/SpeechBrain_Ultra/hparam/Unet_sinc_Hparams.yaml
# yamllint disable
#Some Hyper Params
base_channels: 32
kernel_size_sinc: 125
CHANNEL_NUM: 256
DIM_CNN_MLP: 6746
lr: 0.0001
lr_final: 0.000001
batch_size: 6
number_of_epochs: 100
#Initial Settings

seed: 12345
__set_seed: !apply:torch.manual_seed [12345]
output_folder: Results/Ultrasound_Unet_sinc
save_folder: Results/Ultrasound_Unet_sinc/save
loss_image_folder: Results/Ultrasound_Unet_sinc/LossImages
train_log: Results/Ultrasound_Unet_sinc/train_log.txt
#train_epoch_test_log: !ref <output_folder>/train_epoch_test_log.txt
json_folder: ./json_folder


train_logger: !new:speechbrain.utils.train_logger.FileTrainLogger
  save_file: Results/Ultrasound_Unet_sinc/train_log.txt

train_epoch_test_log: &id001 !new:speechbrain.utils.train_logger.FileTrainLogger


# Data files
  save_file: *id001
train_json: ./json_folder/train.json
valid_json: ./json_folder/valid.json
test_json: ./json_folder/test.json


#sorting: ascending
sorting: random


train_dataloader_opts:
  batch_size: 6
  shuffle: true

valid_dataloader_opts:
  batch_size: 6

test_dataloader_opts:
  batch_size: 6


epoch_counter: &id017 !new:speechbrain.utils.epoch_loop.EpochCounter
  limit: 100

lr_annealing: !new:speechbrain.nnet.schedulers.LinearScheduler
  initial_value: 0.0001
  final_value: 0.000001
  epoch_count: 100

layer1: &id003 !new:speechbrain.nnet.CNN.SincConv
  in_channels: 1
  out_channels: 256
  stride: 2
  sample_rate: 100000000
  kernel_size: 125

layer2: &id005 !new:torch.nn.Conv1d
  in_channels: 1
  out_channels: 256
  kernel_size: 3


layer3: &id008 !new:torch.nn.Conv1d
  in_channels: 256
  out_channels: 256
  kernel_size: 3

layer4: &id009 !new:torch.nn.Conv1d
  in_channels: 256
  out_channels: 1
  kernel_size: 1



Relue: &id004 !new:torch.nn.ReLU
  inplace: true

LeakyRelue: !new:torch.nn.LeakyReLU
  inplace: true


Avg_pooling_1d: !new:torch.nn.AvgPool1d
  kernel_size: 3
  stride: 2

MAX_pooling_1d: &id006 !new:torch.nn.MaxPool1d
  kernel_size: 2

Up_sample: &id007 !new:torch.nn.Upsample
  scale_factor: 2


flatten_L: &id010 !new:torch.nn.Flatten

MLP_L1: &id011 !new:torch.nn.Linear
  in_features: 6746
  out_features: 1



# Optimizer
optim: &id002 !name:torch.optim.Adam
  lr: 0.0001

scheduler: !name:torch.optim.lr_scheduler.LinearLR
  optimizer: *id002
  start_factor: 1.0
  end_factor: 0.5
  total_iters: 30


# Loss function

loss: !new:torch.nn.MSELoss

#Modules

SincBlock: &id012 !new:torch.nn.Sequential
- *id003
- *id004
UPipe: &id013 !new:torch.nn.Sequential
- *id005
- *id004
- *id006
- *id007
RestPipe: &id014 !new:torch.nn.Sequential
- *id008
- *id004
- *id009
- *id004
- *id010
MLPBlock: &id015 !new:torch.nn.Sequential



- *id011
modules:
  SincBlock: *id012
  UPipe: *id013
  RestPipe: *id014
  MLPBlock: *id015
model: &id016 !new:torch.nn.ModuleList
- [*id012, *id013, *id014, *id015]
checkpointer: !new:speechbrain.utils.checkpoints.Checkpointer
  checkpoints_dir: Results/Ultrasound_Unet_sinc/save
  recoverables:
    model: *id016
    counter: *id017
