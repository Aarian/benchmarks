base_channels: 32
kernel_size: 11
CHANNEL_NUM: 256
DIM_CNN_MLP: 277
LR: 0.001


seed: 12345
__set_seed: !apply:torch.manual_seed [!ref <seed>]

padding: !ref <kernel_size> // 2

layer1: !new:torch.nn.Conv1d
  in_channels: 1
  out_channels: !ref <CHANNEL_NUM>
  kernel_size: 4
  stride: 2
  padding: 1

layer2: !new:torch.nn.Conv1d
  in_channels: !ref <CHANNEL_NUM>
  out_channels: !ref <CHANNEL_NUM>//2
  kernel_size: 4
  stride: 2
  padding: 1
  bias: False

layer3: !new:torch.nn.Conv1d
  in_channels: !ref <CHANNEL_NUM>//2
  out_channels: !ref <CHANNEL_NUM>//4
  kernel_size: 4
  stride: 2
  padding: 1
  bias: False

layer4: !new:torch.nn.Conv1d
  in_channels: !ref <CHANNEL_NUM>//4
  out_channels: !ref <CHANNEL_NUM>//8
  kernel_size: 3
  stride: 1
  padding: 1
  bias: False

layer5: !new:torch.nn.Conv1d
  in_channels: !ref <CHANNEL_NUM>//8
  out_channels: 1
  kernel_size: 4
  stride: 1
  padding: 0
  bias: False

Relue: !new:torch.nn.ReLU
  inplace: True

LeakyRelue: !new:torch.nn.LeakyReLU
  inplace: True

Batch_norm_1d_layer_2: !new:torch.nn.BatchNorm1d
  num_features: !ref <CHANNEL_NUM>//2

Batch_norm_1d_layer_3: !new:torch.nn.BatchNorm1d
  num_features: !ref <CHANNEL_NUM>//4

Batch_norm_1d_layer_4: !new:torch.nn.BatchNorm1d
  num_features: !ref <CHANNEL_NUM>//8

Avg_pooling_1d: !new:torch.nn.AvgPool1d
  kernel_size: 3
  stride: 2

Dropout_1d: !new:torch.nn.Dropout1d
  p: 0.5

LayerNorm: !new:torch.nn.LayerNorm
  normalized_shape: !ref <DIM_CNN_MLP>

MLP_L1: !new:torch.nn.Linear
  in_features: !ref <DIM_CNN_MLP>
  out_features: 16

MLP_L2: !new:torch.nn.Linear
  in_features: !ref 16
  out_features: 8

MLP_L3: !new:torch.nn.Linear
  in_features: 8
  out_features: 1

optim: !name:torch.optim.Adam
  lr: !ref <LR>

scheduler: !name:torch.optim.lr_scheduler.LinearLR
  optimizer: !ref <optim>
  start_factor: 1.0
  end_factor: 0.5
  total_iters: 30


model: !new:torch.nn.Sequential
  - !ref <layer1>
  - !ref <Relue>
  - !ref <layer2>
  - !ref <Batch_norm_1d_layer_2>
  - !ref <LeakyRelue>
  - !ref <layer3>
  - !ref <Batch_norm_1d_layer_3>
  - !ref <Relue>
  - !ref <layer4>
  - !ref <Batch_norm_1d_layer_4>
  - !ref <Relue>
  - !ref <Avg_pooling_1d>
  - !ref <Dropout_1d>
  - !ref <layer5>
  - !ref <LeakyRelue>
  - !ref <LayerNorm>
  - !new:torch.nn.Flatten
  - !ref <MLP_L1>
  - !ref <LeakyRelue>
  - !ref <MLP_L2>
  - !ref <LeakyRelue>
  - !ref <MLP_L3>
