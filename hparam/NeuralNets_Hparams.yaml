#Some Hyper Params
base_channels: 32
kernel_size: 11
CHANNEL_NUM: 256
DIM_CNN_MLP: 277
LR: 0.001
batch_size: 2
number_of_epochs: 1
#Initial Settings

seed: 12345
__set_seed: !apply:torch.manual_seed [!ref <seed>]
output_folder: !ref Results/Ultrasound/
save_folder: !ref <output_folder>/save
train_log: !ref <output_folder>/train_log.txt
json_folder: !ref ./json_folder

#padding: !ref <kernel_size> // 2

# Data files
train_json: !ref <json_folder>/train.json
valid_json: !ref <json_folder>/valid.json
test_json: !ref <json_folder>/test.json


sorting: ascending


train_dataloader_opts:
    batch_size: !ref <batch_size>
    shuffle: True
    
valid_dataloader_opts:
   batch_size: !ref <batch_size>

test_dataloader_opts:
   batch_size: !ref <batch_size>

# # CNN Neural Network

# layer1: !new:speechbrain.nnet.CNN.Conv1d #!new:torch.nn.Conv1d
#   in_channels: 1
#   out_channels: !ref <CHANNEL_NUM>
#   kernel_size: 4
#   stride: 2
#   #padding: 1

# layer2: !new:speechbrain.nnet.CNN.Conv1d #!new:torch.nn.Conv1d
#   in_channels: !ref <CHANNEL_NUM>
#   out_channels: !ref <CHANNEL_NUM>//2
#   kernel_size: 4
#   stride: 2
#   #padding: 1
#   bias: False

# layer3: !new:speechbrain.nnet.CNN.Conv1d #!new:torch.nn.Conv1d
#   in_channels: !ref <CHANNEL_NUM>//2
#   out_channels: !ref <CHANNEL_NUM>//4
#   kernel_size: 4
#   stride: 2
#   #padding: 1
#   bias: False

# layer4: !new:speechbrain.nnet.CNN.Conv1d #!new:torch.nn.Conv1d
#   in_channels: !ref <CHANNEL_NUM>//4
#   out_channels: !ref <CHANNEL_NUM>//8
#   kernel_size: 3
#   stride: 1
#   #padding: 1
#   bias: False

# layer5: !new:speechbrain.nnet.CNN.Conv1d #!new:torch.nn.Conv1d
#   in_channels: !ref <CHANNEL_NUM>//8
#   out_channels: 1
#   kernel_size: 4
#   stride: 1
#   #padding: 0
#   bias: False


epoch_counter: !new:speechbrain.utils.epoch_loop.EpochCounter
    limit: !ref <number_of_epochs>

layer1: !new:torch.nn.Conv1d
  in_channels: 1
  out_channels: !ref <CHANNEL_NUM>
  kernel_size: 4
  stride: 2
  padding: 1

layer2: !new:torch.nn.Conv1d
  in_channels: !ref <CHANNEL_NUM>
  out_channels: !ref <CHANNEL_NUM>//2
  kernel_size: 4
  stride: 2
  padding: 1
  bias: False

layer3: !new:torch.nn.Conv1d
  in_channels: !ref <CHANNEL_NUM>//2
  out_channels: !ref <CHANNEL_NUM>//4
  kernel_size: 4
  stride: 2
  padding: 1
  bias: False

layer4: !new:torch.nn.Conv1d
  in_channels: !ref <CHANNEL_NUM>//4
  out_channels: !ref <CHANNEL_NUM>//8
  kernel_size: 3
  stride: 1
  padding: 1
  bias: False

layer5: !new:torch.nn.Conv1d
  in_channels: !ref <CHANNEL_NUM>//8
  out_channels: 1
  kernel_size: 4
  stride: 1
  padding: 0
  bias: False


Relue: !new:torch.nn.ReLU
  inplace: True

LeakyRelue: !new:torch.nn.LeakyReLU
  inplace: True

Batch_norm_1d_layer_2: !new:torch.nn.BatchNorm1d
  num_features: !ref <CHANNEL_NUM>//2

Batch_norm_1d_layer_3: !new:torch.nn.BatchNorm1d
  num_features: !ref <CHANNEL_NUM>//4

Batch_norm_1d_layer_4: !new:torch.nn.BatchNorm1d
  num_features: !ref <CHANNEL_NUM>//8

Avg_pooling_1d: !new:torch.nn.AvgPool1d
  kernel_size: 3
  stride: 2

Dropout_1d: !new:torch.nn.Dropout1d
  p: 0.5

LayerNorm: !new:torch.nn.LayerNorm
  normalized_shape: !ref <DIM_CNN_MLP>

flatten_L: !new:torch.nn.Flatten

MLP_L1: !new:torch.nn.Linear
  in_features: !ref <DIM_CNN_MLP>
  out_features: 16

MLP_L2: !new:torch.nn.Linear
  in_features: 16
  out_features: 8

MLP_L3: !new:torch.nn.Linear
  in_features: 8
  out_features: 1


# Optimizer
optim: !name:torch.optim.Adam
  lr: !ref <LR>

scheduler: !name:torch.optim.lr_scheduler.LinearLR
  optimizer: !ref <optim>
  start_factor: 1.0
  end_factor: 0.5
  total_iters: 30


# Loss function

loss: !new:torch.nn.MSELoss

#Modules

CnnBlock: !new:torch.nn.Sequential
  - !ref <layer1>
  - !ref <Relue>
  - !ref <layer2>
  - !ref <Batch_norm_1d_layer_2>
  - !ref <LeakyRelue>
  - !ref <layer3>
  - !ref <Batch_norm_1d_layer_3>
  - !ref <Relue>
  - !ref <layer4>
  - !ref <Batch_norm_1d_layer_4>
  - !ref <Relue>
  - !ref <Avg_pooling_1d>
  - !ref <Dropout_1d>
  - !ref <layer5>
  - !ref <LeakyRelue>
  - !ref <LayerNorm>
  - !ref <flatten_L> 

MLPBlock: !new:torch.nn.Sequential
  - !ref <MLP_L1>
  - !ref <LeakyRelue>
  - !ref <MLP_L2>
  - !ref <LeakyRelue>
  - !ref <MLP_L3>

modules:
  CnnBlock: !ref <CnnBlock>
  #flatten_L: !ref <flatten_L>
  MLPBlock: !ref <MLPBlock>


# Model




# model: !new:torch.nn.Sequential
#   - !ref <layer1>
#   - !ref <Relue>
#   - !ref <layer2>
#   - !ref <Batch_norm_1d_layer_2>
#   - !ref <LeakyRelue>
#   - !ref <layer3>
#   - !ref <Batch_norm_1d_layer_3>
#   - !ref <Relue>
#   - !ref <layer4>
#   - !ref <Batch_norm_1d_layer_4>
#   - !ref <Relue>
#   - !ref <Avg_pooling_1d>
#   - !ref <Dropout_1d>
#   - !ref <layer5>
#   - !ref <LeakyRelue>
#   - !ref <LayerNorm>
#   - !new:torch.nn.Flatten
#   - !ref <MLP_L1>
#   - !ref <LeakyRelue>
#   - !ref <MLP_L2>
#   - !ref <LeakyRelue>
#   - !ref <MLP_L3>


model: !new:torch.nn.ModuleList
- [!ref <CnnBlock>, !ref <MLPBlock>]

#  model: !new:torch.nn.Sequential
#    - !ref <CnnBlock>
#    - !ref <flatten_L>
#    - !ref <MLPBlock>







###### Check pointing

checkpointer: !new:speechbrain.utils.checkpoints.Checkpointer
    checkpoints_dir: !ref <save_folder>
    recoverables:
        model: !ref <model>
        counter: !ref <epoch_counter>